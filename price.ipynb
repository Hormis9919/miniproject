{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72f1d3b-1c93-4683-8cb0-d76006aa5fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters for Random Forest: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "Models saved successfully as 'random_forest.pkl' and 'extra_trees.pkl'!\n",
      "Random Forest - MAE: 60993.9346, MSE: 11385461840.0319, RMSE: 106702.6796, RÂ²: 0.9836, Accuracy: 98.36%, MAPE: 14.67%\n",
      "\n",
      "Extra Trees - MAE: 60685.5792, MSE: 13815884054.2931, RMSE: 117540.9888, RÂ²: 0.9801, Accuracy: 98.01%, MAPE: 14.83%\n",
      "\n",
      "\n",
      "ðŸ”¹ Optimized Weights - Random Forest: 0.67, Extra Trees: 0.33\n",
      "Optimized Weighted Averaged Model - MAE: 59254.6855, MSE: 10565706502.7417, RMSE: 102789.6225, RÂ²: 0.9848, Accuracy: 98.48%, MAPE: 14.49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Car details v3.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Convert categorical variables to numerical using One-Hot Encoding\n",
    "categorical_cols = ['fuel', 'seller_type', 'transmission', 'owner']  # Adjust if needed\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Now, we can define X and y\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Convert 'mileage' column to numeric (remove 'kmpl')\n",
    "# Convert 'mileage' column to numeric, handling both 'kmpl' and 'km/kg'\n",
    "df['mileage'] = df['mileage'].str.replace(' kmpl', '', regex=True)\n",
    "df['mileage'] = df['mileage'].str.replace(' km/kg', '', regex=True)\n",
    "df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce')  # Convert to float\n",
    "\n",
    "\n",
    "# Convert 'engine' column to numeric (remove 'CC')\n",
    "df['engine'] = df['engine'].str.replace(' CC', '', regex=True).astype(float)\n",
    "\n",
    "# Convert 'max_power' column to numeric (remove 'bhp')\n",
    "df['max_power'] = df['max_power'].str.replace(' bhp', '', regex=True).astype(float)\n",
    "\n",
    "# Extract the first numeric value from 'torque' column (ignoring '@' values)\n",
    "df['torque'] = df['torque'].str.split(' ').str[0]  # Keep only the first number\n",
    "df['torque'] = pd.to_numeric(df['torque'], errors='coerce')  # Convert to float\n",
    "\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['selling_price', 'name'])  # Drop 'selling_price' (target) and 'name' (not useful)\n",
    "y = df['selling_price']\n",
    "\n",
    "# Split into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Hyper parameter training\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Optimize Random Forest using RandomizedSearchCV\n",
    "rf_cv = RandomizedSearchCV(RandomForestRegressor(), param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters for Random Forest:\", rf_cv.best_params_)\n",
    "\n",
    "# Train Random Forest with the best parameters\n",
    "rf_model = RandomForestRegressor(**rf_cv.best_params_, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Extra Trees Regressor\n",
    "et_model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_et = et_model.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Function to evaluate models with additional metrics\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)  # Accuracy metric\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Percentage error\n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, RÂ²: {r2:.4f}, Accuracy: {r2 * 100:.2f}%, MAPE: {mape:.2f}%\\n\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(rf_model, \"random_forest.pkl\")\n",
    "joblib.dump(et_model, \"extra_trees.pkl\")\n",
    "\n",
    "print(\"Models saved successfully as 'random_forest.pkl' and 'extra_trees.pkl'!\")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate Random Forest\n",
    "evaluate_model(y_test, rf_model.predict(X_test), \"Random Forest\")\n",
    "\n",
    "# Evaluate Extra Trees\n",
    "evaluate_model(y_test, et_model.predict(X_test), \"Extra Trees\")\n",
    "\n",
    "# Average model predictions using weighted  soft voting\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define loss function (Minimize RMSE)\n",
    "def loss_function(weights):\n",
    "    weighted_pred = (weights[0] * rf_model.predict(X_test)) + (weights[1] * et_model.predict(X_test))\n",
    "    return np.sqrt(mean_squared_error(y_test, weighted_pred))  # RMSE is used as metric\n",
    "\n",
    "# Constraints: Weights should sum to 1\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: w[0] + w[1] - 1})\n",
    "bounds = [(0, 1), (0, 1)]  # Weights should be between 0 and 1\n",
    "\n",
    "# Optimize weights\n",
    "initial_weights = [0.5, 0.5]  # Start with equal weights\n",
    "optimized_weights = minimize(loss_function, initial_weights, bounds=bounds, constraints=constraints)\n",
    "rf_weight, et_weight = optimized_weights.x\n",
    "\n",
    "print(f\"\\nðŸ”¹ Optimized Weights - Random Forest: {rf_weight:.2f}, Extra Trees: {et_weight:.2f}\")\n",
    "\n",
    "# Apply optimized weights to get final predictions\n",
    "y_pred_weighted = (rf_weight * rf_model.predict(X_test)) + (et_weight * et_model.predict(X_test))\n",
    "evaluate_model(y_test, y_pred_weighted, \"Optimized Weighted Averaged Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e6daf-0552-4d83-8ddc-c214780ff7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
